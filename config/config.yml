# General configuration for Meta-Mar LLM

llm:
  gpt4:
    model: "gpt-4-turbo-preview"
    temperature: 0.3
    max_tokens: 1000
    timeout: 30
  
  claude:
    model: "claude-3-opus-20240229"
    temperature: 0.3
    max_tokens: 1000
    timeout: 30

api:
  retry_attempts: 3
  retry_delay: 1
  batch_size: 10
  rate_limit: 100

shiny:
  port: 3838
  host: "127.0.0.1"
  max_upload_size: 5242880  # 5MB

storage:
  results_dir: "results"
  cache_dir: "cache"
  max_cache_size: 1073741824  # 1GB